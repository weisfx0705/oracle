
import { GoogleGenAI, Modality } from "@google/genai";
import { Poem } from "../types";

const API_KEY = process.env.API_KEY || "";

export const getGeminiInterpretation = async (apiKey: string, question: string, poem: Poem): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey });
  const poemText = poem.content.join("ï¼Œ");
  const prompt = `
    ç”¨æˆ¶çš„å•é¡Œæ˜¯ï¼šã€Œ${question}ã€
    æŠ½åˆ°çš„è§€éŸ³éˆç±¤æ˜¯ç¬¬ ${poem.id} ç±¤ï¼š
    ç±¤è©©å…§å®¹ï¼š${poemText}
    
    è«‹ä½ ä½œç‚ºä¸€ä½ç²¾é€šå‘½ç†ä½†ã€Œéå¸¸ç¾ä»£åŒ–ã€ä¸”ã€Œå¹½é»˜é¢¨è¶£ã€çš„å¤§å¸«é€²è¡Œè§£ç±¤ã€‚
    
    è¦æ±‚ç´°ç¯€ï¼š
    1. èªªè©±æ–¹å¼è¦åƒç¾ä»£äººï¼Œå¯ä»¥æ¯’èˆŒã€å¯ä»¥åæ§½ã€å¯ä»¥å¹½é»˜ï¼Œä½†æ ¸å¿ƒè¦ä¸€é‡è¦‹è¡€ã€‚
    2. é©åº¦ä½¿ç”¨è±å¯Œçš„è¡¨æƒ…ç¬¦è™Ÿ (emoji) å¢åŠ è¦ªåˆ‡æ„Ÿã€‚
    3. é‡å°ç”¨æˆ¶çš„å•é¡Œï¼Œç›´æ¥çµ¦å‡ºæœ€çœŸå¯¦ï¼ˆç”šè‡³æœ‰é»æ‰å¿ƒï¼‰çš„å»ºè­°ï¼Œä¸è¦è€ç”Ÿå¸¸è«‡ã€‚
    4. å…§å®¹è«‹åŒ…å«ï¼šã€å¤§å¸«åæ§½ã€‘ã€ã€ç±¤è©©ç¾ä»£ç™½è©±ç¿»è­¯ã€‘ã€ã€çµ¦ä½ çš„ç¥å»ºè­°ã€‘ã€‚
    5. ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸¦ç”¨ç°¡å–®çš„ Markdown æ ¼å¼å›å‚³ï¼ˆä½¿ç”¨ ## æ¨™é¡Œèˆ‡ç²—é«”ï¼‰ã€‚
  `;

  try {
    const response = await ai.models.generateContent({
      model: "gemini-3-flash-preview",
      contents: prompt,
      config: {
        temperature: 0.9,
        topP: 0.95,
      }
    });
    return response.text || "å¤§å¸«å»è²·å’–å•¡äº†ï¼Œç­‰æœƒå†èªªã€‚â˜•ï¸";
  } catch (error) {
    console.error("Gemini Error:", error);
    return "è¨Šè™Ÿä¸å¤ªå¥½ï¼Œå¤§æ¦‚æ˜¯éˆç•ŒåŸºåœ°å°ç¶­ä¿®ä¸­ã€‚ğŸ›°ï¸";
  }
};

export const generatePoemImage = async (apiKey: string, poem: Poem, customStyle: string = "3D paper cutting art style with exquisite layers"): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey });
  const poemText = poem.content.join(" ");
  // å¼·åŒ–æç¤ºè©ï¼Œåš´ç¦å‡ºç¾ä»»ä½•å½¢å¼çš„æ–‡å­—ã€å­—æ¯æˆ–æ•¸å­—
  const prompt = `A mystical dark-themed oracle card, ${customStyle}, the art depicts the essence of: "${poemText}". Dark ambient atmosphere, backlit with sacred golden and deep blue light, paper textures or artistic strokes, holy but moody vibes. ABSOLUTELY NO TEXT, NO LETTERS, NO NUMBERS, NO CHARACTERS, NO WORDS, ONLY PURE ARTWORK.`;

  try {
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-image",
      contents: { parts: [{ text: prompt }] },
      config: {
        imageConfig: {
          aspectRatio: "3:4"
        }
      }
    });

    for (const part of response.candidates?.[0]?.content?.parts || []) {
      if (part.inlineData) {
        return `data:image/png;base64,${part.inlineData.data}`;
      }
    }
    return "";
  } catch (error) {
    console.error("Image Generation Error:", error);
    return "";
  }
};

// --- TTS Helpers ---
// --- TTS Helpers ---
function decodeBase64(base64: string) {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

function writeString(view: DataView, offset: number, string: string) {
  for (let i = 0; i < string.length; i++) {
    view.setUint8(offset + i, string.charCodeAt(i));
  }
}

function createWavBlob(samples: Uint8Array, sampleRate: number, numChannels: number): Blob {
  const buffer = new ArrayBuffer(44 + samples.length);
  const view = new DataView(buffer);

  // RIFF identifier
  writeString(view, 0, 'RIFF');
  // file length
  view.setUint32(4, 36 + samples.length, true);
  // RIFF type
  writeString(view, 8, 'WAVE');
  // format chunk identifier
  writeString(view, 12, 'fmt ');
  // format chunk length
  view.setUint32(16, 16, true);
  // sample format (raw)
  view.setUint16(20, 1, true);
  // channel count
  view.setUint16(22, numChannels, true);
  // sample rate
  view.setUint32(24, sampleRate, true);
  // byte rate (sampleRate * blockAlign)
  view.setUint32(28, sampleRate * numChannels * 2, true);
  // block align (channel count * bytes per sample)
  view.setUint16(32, numChannels * 2, true);
  // bits per sample
  view.setUint16(34, 16, true);
  // data chunk identifier
  writeString(view, 36, 'data');
  // data chunk length
  view.setUint32(40, samples.length, true);

  // write the PCM samples
  const rawBytes = new Uint8Array(buffer);
  rawBytes.set(samples, 44);

  return new Blob([buffer], { type: 'audio/wav' });
}

async function decodeAudioData(
  data: Uint8Array,
  ctx: AudioContext,
  sampleRate: number,
  numChannels: number,
): Promise<AudioBuffer> {
  const dataInt16 = new Int16Array(data.buffer);
  const frameCount = dataInt16.length / numChannels;
  const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);

  for (let channel = 0; channel < numChannels; channel++) {
    const channelData = buffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
    }
  }
  return buffer;
}

export const generateInterpretationAudio = async (
  apiKey: string,
  interpretation: string,
  existingContext?: AudioContext
): Promise<{ buffer: AudioBuffer, blob: Blob } | null> => {
  const ai = new GoogleGenAI({ apiKey });

  // 1. å…ˆç”Ÿæˆ 150 å­—çš„å¹½é»˜ç¸½çµæ–‡æœ¬
  const summaryResponse = await ai.models.generateContent({
    model: "gemini-3-flash-preview",
    contents: `è«‹å°‡ä»¥ä¸‹è§£ç±¤å…§å®¹ç¸½çµæˆä¸€æ®µç´„ 150 å­—çš„å£èªç¨¿ã€‚
    è¦æ±‚ï¼šå°ç£å¹´è¼•ç”·æ€§çš„å£å»ï¼Œèªæ°£éå¸¸ç¾ä»£ã€å¹½é»˜ã€é¢¨è¶£ä¸”å¸¶é»ã€Œæ´¾ã€çš„æ„Ÿè¦ºï¼Œèªªè©±è¦æœ‰åŠ›ã€é€Ÿåº¦å¿«ã€æƒ…ç·’èµ·ä¼å¤§ã€‚
    å…§å®¹è¦ç¹é«”ä¸­æ–‡ï¼Œä¸”é©åˆæœ—è®€ã€‚
    è§£ç±¤å…§å®¹ï¼š${interpretation}`,
  });

  const summaryText = summaryResponse.text || "å–‚ï¼è½å¥½äº†ï¼Œå¤§å¸«å«ä½ æ”¾è¼•é¬†é»ã€‚";

  // 2. å°‡æ–‡æœ¬è½‰ç‚ºèªéŸ³
  try {
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-preview-tts",
      contents: [{ parts: [{ text: `å”¸å‡ºé€™æ®µæ–‡å­—ï¼Œè¦æ±‚å°ç£å£éŸ³ã€å¹´è¼•æ´»åŠ›çš„è²éŸ³ã€æƒ…ç·’é£½æ»¿ä¸”èªé€Ÿè¼•å¿«ï¼š${summaryText}` }] }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: {
          voiceConfig: {
            // Puck æ˜¯æ¯”è¼ƒå¹´è¼•æ´»æ½‘çš„ç”·è²
            prebuiltVoiceConfig: { voiceName: 'Puck' },
          },
        },
      },
    });

    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (base64Audio) {
      const rawData = decodeBase64(base64Audio);
      // Use existing context if provided, otherwise create a temporary one for decoding
      const audioCtx = existingContext || new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });

      const audioBuffer = await decodeAudioData(
        rawData,
        audioCtx,
        24000,
        1,
      );

      const audioBlob = createWavBlob(rawData, 24000, 1);

      return { buffer: audioBuffer, blob: audioBlob };
    }
  } catch (error) {
    console.error("TTS Error:", error);
  }
  return null;
};
